{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "successful-triangle",
   "metadata": {},
   "source": [
    "# 02.1 - ML Experimentation with AutoML\n",
    "\n",
    "The purpose of this notebook is to use [AutoML Tables](https://cloud.google.com/automl-tables) to train a classifier \n",
    "to predict whether a given trip will result in a tip > 20%. The notebook covers the following tasks:\n",
    "1. Retrieves the managed Dataset uri to be used for training.\n",
    "2. Prepare and submit an AutoMl Tables training job.\n",
    "3. Retrieves the uploaded model by the AutoMl Tables.\n",
    "3. Retrieves the evaluation results of the AutoML Table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-cincinnati",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import tensorflow_data_validation as tfdv\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "from google.cloud.aiplatform import gapic as aip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'ksalama-cloudml'  # Change to your project Id.\n",
    "REGION = 'us-central1'\n",
    "\n",
    "DATASET_DISPLAYNAME = 'chicago_taxi_tips'\n",
    "AUTOML_MODEL_DISPLAYNAME = f'{DATASET_DISPLAYNAME}_classifier_automl'\n",
    "API_ENDPOINT = f\"{REGION}-aiplatform.googleapis.com\"\n",
    "PARENT = f\"projects/{PROJECT}/locations/{REGION}\"\n",
    "\n",
    "client_options = {\"api_endpoint\": API_ENDPOINT}\n",
    "\n",
    "RAW_SCHEMA_DIR = 'model_src/raw_schema/schema.pbtxt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-analyst",
   "metadata": {},
   "source": [
    "## 1. Get Managed Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-hungarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_client = aip.DatasetServiceClient(client_options=client_options)\n",
    "for dataset in dataset_client.list_datasets(parent=PARENT):\n",
    "    if dataset.display_name == DATASET_DISPLAYNAME:\n",
    "        dataset_uri = dataset.name\n",
    "        break\n",
    "        \n",
    "dataset = dataset_client.get_dataset(name=dataset_uri)\n",
    "print(\"Dataset uri:\", dataset.name)\n",
    "dataset_id = dataset.name.split('/')[-1]\n",
    "print(\"Dataset id:\", dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-windows",
   "metadata": {},
   "source": [
    "## 2. Train a classifier using AutoML Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-falls",
   "metadata": {},
   "source": [
    "### Load raw schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'tip_bin'\n",
    "data_split_column = 'data_split'\n",
    "exclude_cloumns = ['trip_start_timestamp']\n",
    "\n",
    "source_raw_schema = tfdv.load_schema_text(RAW_SCHEMA_DIR)\n",
    "raw_feature_spec = schema_utils.schema_as_feature_spec(source_raw_schema).feature_spec\n",
    "input_columns = [key for key in raw_feature_spec if key not in exclude_cloumns]\n",
    "input_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-tsunami",
   "metadata": {},
   "source": [
    "### Prepare AutoML Tables training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-provincial",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "\n",
    "\n",
    "def train_automl_table(\n",
    "    automl_pipeline_client,\n",
    "    parent,\n",
    "    dataset_id,\n",
    "    model_display_name,\n",
    "    input_columns,\n",
    "    target_column\n",
    "):\n",
    "    transformations = [\n",
    "        {\"auto\": {\"column_name\": column}} \n",
    "        for column in input_columns\n",
    "    ]\n",
    "\n",
    "    training_task_inputs_dict = {\n",
    "        \"targetColumn\": target_column,\n",
    "        \"predictionType\": \"classification\",\n",
    "        \"transformations\": transformations,\n",
    "        \"trainBudgetMilliNodeHours\": 1,\n",
    "        \"disableEarlyStopping\": False,\n",
    "        \"optimizationObjective\": \"minimize-log-loss\",\n",
    "    }\n",
    "    training_task_inputs = json_format.ParseDict(training_task_inputs_dict, Value())\n",
    "\n",
    "    training_pipeline = {\n",
    "        \"display_name\": f\"train_{model_display_name}_{datetime.now().strftime('%Y%m%d%H%M%S')}\",\n",
    "        \"training_task_definition\": \"gs://google-cloud-aiplatform/schema/trainingjob/definition/automl_tabular_1.0.0.yaml\",\n",
    "        \"training_task_inputs\": training_task_inputs,\n",
    "        \"input_data_config\": {\n",
    "            \"dataset_id\": dataset_id,\n",
    "#             \"fraction_split\": {\n",
    "#                 \"training_fraction\": 0.8,\n",
    "#                 \"validation_fraction\": 0.1,\n",
    "#                 \"test_fraction\": 0.1,\n",
    "#             },\n",
    "            \"predefined_split\": {\n",
    "               \"key\": data_split_column \n",
    "            }\n",
    "            \n",
    "        },\n",
    "        \"model_to_upload\": {\"display_name\": model_display_name},\n",
    "    }\n",
    "\n",
    "    response = automl_pipeline_client.create_training_pipeline(\n",
    "        parent=parent, training_pipeline=training_pipeline\n",
    "    )\n",
    "    \n",
    "    print(\"response:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-geology",
   "metadata": {},
   "source": [
    "### Submit AutoML Tables training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-acceptance",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_pipeline_client = aip.PipelineServiceClient(\n",
    "    client_options=client_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-union",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_automl_table(\n",
    "    automl_pipeline_client=automl_pipeline_client,\n",
    "    parent=PARENT,\n",
    "    dataset_id=dataset_id,\n",
    "    model_display_name=AUTOML_MODEL_DISPLAYNAME,\n",
    "    input_columns=input_columns,\n",
    "    target_column=target_column\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_pipeline_client.create_training_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-figure",
   "metadata": {},
   "source": [
    "### List training jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-mechanics",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = automl_pipeline_client.list_training_pipelines(parent=PARENT)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-finish",
   "metadata": {},
   "source": [
    "## 3. Retrieve the Uploaded Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-huntington",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_client = aip.ModelServiceClient(client_options=client_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-concert",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = model_client.list_models(parent=PARENT)\n",
    "\n",
    "for entry in model_list:\n",
    "    if entry.display_name == AUTOML_MODEL_DISPLAYNAME:\n",
    "        model_uri = entry.name\n",
    "        break\n",
    "\n",
    "print(model_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-atlantic",
   "metadata": {},
   "source": [
    "## 4. Get Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-season",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = model_client.list_model_evaluations(parent=model_uri)\n",
    "evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = list(evaluation_results)[0].metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-bidder",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(metrics.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-arlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Log loss:\", metrics['logLoss'])\n",
    "print(\"AUC - PRC:\", metrics['auPrc'])\n",
    "print(\"AUC - ROC:\", metrics['auRoc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = metrics['confusionMatrix']['rows']\n",
    "\n",
    "print(\"TN:\", entries[0][0])\n",
    "print(\"FP:\", entries[0][1])\n",
    "print(\"FN:\", entries[1][0])\n",
    "print(\"TP:\", entries[1][1])\n",
    "\n",
    "total = sum(entries[0]) + sum(entries[1])\n",
    "accuracy = (entries[0][0] + entries[1][1]) / total\n",
    "\n",
    "print(f\"Accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_metrics = list(evaluation_results)[0].metrics['confidenceMetrics']\n",
    "list(confidence_metrics[-1].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-scene",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = []\n",
    "scores = []\n",
    "\n",
    "for m in confidence_metrics:\n",
    "    entry = dict(m)\n",
    "    f1Score = entry['f1Score']\n",
    "    threshold = 0\n",
    "    \n",
    "    if 'confidenceThreshold' in entry:\n",
    "        threshold = entry['confidenceThreshold']\n",
    "        \n",
    "    thresholds.append(threshold)\n",
    "    scores.append(f1Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-resolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        'threshold': thresholds,\n",
    "        'score': scores\n",
    "    }\n",
    ").plot(kind='line', x='threshold', y='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-meter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

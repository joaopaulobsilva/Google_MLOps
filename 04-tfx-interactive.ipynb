{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "central-charlotte",
   "metadata": {},
   "source": [
    "# TFX - Interactive Training Pipeline\n",
    "\n",
    "The purpose of this notebook is to interactively run the following TFX pipeline steps:\n",
    "1. Receive hyperparameters using hyperparam_gen custom python component\n",
    "2. Extract data from BigQuery using BigQueryExampleGen\n",
    "3. Validate the raw data using StatisticsGen and ExampleValidator\n",
    "4. Process the data using Transform\n",
    "5. Train a custom model using Trainer\n",
    "6. Train an AutoML Tables model using automl_trainer custom python component\n",
    "7. Evaluat the custom model using ModelEvaluator\n",
    "8. Validate the custom model against the AutoML Tables model using a custom python component\n",
    "7. Save the blessed to model registry location using using Pusher\n",
    "8. Upload the model to AI Platform using aip_model_pusher custom python component\n",
    "\n",
    "The custom components are implemented in the [tfx_pipeline/components.py](tfx_pipeline/components) module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-repeat",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tfx\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "import tensorflow_data_validation as tfdv\n",
    "import tensorflow_model_analysis as tfma\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "import logging\n",
    "\n",
    "from model_src import data, features\n",
    "from tfx_pipeline import components\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "print(\"Tensorflow Version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-negotiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'ksalama-cloudml'\n",
    "REGION = 'us-central1'\n",
    "BUCKET = 'ksalama-cloudml-us'\n",
    "\n",
    "DATASET_DISPLAYNAME = 'chicago_taxi_tips'\n",
    "CUSTOM_MODEL_DISPLAYNAME = f'{DATASET_DISPLAYNAME}_classifier_custom'\n",
    "AUTOML_MODEL_DISPLAYNAME = f'{DATASET_DISPLAYNAME}_classifier_automl'\n",
    "\n",
    "WORKSPACE = f\"gs://{BUCKET}/ucaip_demo/chicago_taxi/pipelines_interactive\"\n",
    "RAW_SCHEMA_DIR = 'model_src/raw_schema'\n",
    "\n",
    "MLMD_SQLLITE = 'mlmd.sqllite'\n",
    "ARTIFACT_STORE = os.path.join(WORKSPACE, 'tfx_artifacts')\n",
    "MODEL_REGISTRY = os.path.join(WORKSPACE, 'model_registry')\n",
    "PIPELINE_NAME = f'{DATASET_DISPLAYNAME}_training_pipeline'\n",
    "PIPELINE_ROOT = os.path.join(ARTIFACT_STORE, PIPELINE_NAME)\n",
    "\n",
    "!gcloud config set project $PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-melissa",
   "metadata": {},
   "source": [
    "## Create Interactive Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-examination",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN_ARTIFACTS = True\n",
    "if tf.io.gfile.exists(ARTIFACT_STORE) and CLEAN_ARTIFACTS:\n",
    "    print(\"Removing previous artifacts...\")\n",
    "    tf.io.gfile.rmtree(ARTIFACT_STORE)\n",
    "    \n",
    "if tf.io.gfile.exists(MLMD_SQLLITE) and CLEAN_ARTIFACTS:\n",
    "    print(\"Deleting previous mlmd.sqllite...\")\n",
    "    tf.io.gfile.rmtree(ARTIFACT_STORE)\n",
    "\n",
    "if not tf.io.gfile.exists(ARTIFACT_STORE):\n",
    "    print(\"Creating local tfx artifact directory...\")\n",
    "    tf.io.gfile.mkdir(ARTIFACT_STORE)\n",
    "    \n",
    "print(f'Pipeline artifacts directory: {PIPELINE_ROOT}')\n",
    "print(f'Local metadata SQLlit path: {MLMD_SQLLITE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-dodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_metadata as mlmd\n",
    "from ml_metadata.proto import metadata_store_pb2\n",
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "\n",
    "connection_config = metadata_store_pb2.ConnectionConfig()\n",
    "connection_config.sqlite.filename_uri = MLMD_SQLLITE\n",
    "connection_config.sqlite.connection_mode = 3 # READWRITE_OPENCREATE\n",
    "mlmd_store = mlmd.metadata_store.MetadataStore(connection_config)\n",
    "\n",
    "context = InteractiveContext(\n",
    "  pipeline_name=PIPELINE_NAME,\n",
    "  pipeline_root=PIPELINE_ROOT,\n",
    "  metadata_connection_config=connection_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-march",
   "metadata": {},
   "source": [
    "## 1. Hyperparameter Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams_gen = components.hyperparameters_gen(\n",
    "    num_epochs=5,\n",
    "    learning_rate=0.001,\n",
    "    batch_size=512,\n",
    "    hidden_units='64,64',\n",
    ")\n",
    "\n",
    "context.run(hyperparams_gen, enable_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-italic",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.load(\n",
    "    tf.io.gfile.GFile(\n",
    "        os.path.join(\n",
    "            hyperparams_gen.outputs.hyperparameters.get()[0].uri, 'hyperparameters.json')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-present",
   "metadata": {},
   "source": [
    "## 2. Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import datasource_utils\n",
    "from tfx.extensions.google_cloud_big_query.example_gen.component import BigQueryExampleGen\n",
    "from tfx.proto import example_gen_pb2, transform_pb2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-marsh",
   "metadata": {},
   "source": [
    "### Extract train and eval splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = datasource_utils.get_source_query(\n",
    "    PROJECT, REGION, DATASET_DISPLAYNAME, data_split='UNASSIGNED', limit=10000)\n",
    "\n",
    "output_config = example_gen_pb2.Output(\n",
    "    split_config=example_gen_pb2.SplitConfig(\n",
    "        splits=[\n",
    "            example_gen_pb2.SplitConfig.Split(name=\"train\", hash_buckets=4),\n",
    "            example_gen_pb2.SplitConfig.Split(name=\"eval\", hash_buckets=1),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "train_example_gen = BigQueryExampleGen(query=sql_query, output_config=output_config)\n",
    "\n",
    "beam_pipeline_args=[\n",
    "    f\"--project={PROJECT}\",\n",
    "    f\"--temp_location=gs://{BUCKET}/bq_tmp\"\n",
    "]\n",
    "\n",
    "context.run(\n",
    "    train_example_gen,\n",
    "    beam_pipeline_args=beam_pipeline_args,\n",
    "    enable_cache=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-partner",
   "metadata": {},
   "source": [
    "### Extract test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-academy",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = datasource_utils.get_source_query(\n",
    "    PROJECT, REGION, DATASET_DISPLAYNAME, data_split='TEST', limit=1000)\n",
    "\n",
    "output_config = example_gen_pb2.Output(\n",
    "    split_config=example_gen_pb2.SplitConfig(\n",
    "        splits=[\n",
    "            example_gen_pb2.SplitConfig.Split(name=\"test\", hash_buckets=1),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "test_example_gen = BigQueryExampleGen(query=sql_query, output_config=output_config)\n",
    "\n",
    "beam_pipeline_args=[\n",
    "    f\"--project={PROJECT}\",\n",
    "    f\"--temp_location=gs://{BUCKET}/bq_tmp\"\n",
    "]\n",
    "\n",
    "context.run(\n",
    "    test_example_gen,\n",
    "    beam_pipeline_args=beam_pipeline_args,\n",
    "    enable_cache=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_uri = os.path.join(train_example_gen.outputs.examples.get()[0].uri, \"train/*\")\n",
    "print(train_uri)\n",
    "\n",
    "source_raw_schema = tfdv.load_schema_text(os.path.join(RAW_SCHEMA_DIR, 'schema.pbtxt'))\n",
    "raw_feature_spec = schema_utils.schema_as_feature_spec(source_raw_schema).feature_spec\n",
    "\n",
    "def _parse_tf_example(tfrecord):\n",
    "    return tf.io.parse_single_example(tfrecord, raw_feature_spec)\n",
    "\n",
    "tfrecord_filenames = tf.data.Dataset.list_files(train_uri)\n",
    "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
    "dataset = dataset.map(_parse_tf_example)\n",
    "\n",
    "for raw_features in dataset.shuffle(1000).batch(3).take(1):\n",
    "    for key in raw_features:\n",
    "        print(f\"{key}: {np.squeeze(raw_features[key], -1)}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-resource",
   "metadata": {},
   "source": [
    "## 3. Data Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-potter",
   "metadata": {},
   "source": [
    "### Import raw schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-interpretation",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_importer = tfx.components.common_nodes.importer_node.ImporterNode(\n",
    "    instance_name='Schema_Importer',\n",
    "    source_uri=RAW_SCHEMA_DIR,\n",
    "    artifact_type=tfx.types.standard_artifacts.Schema,\n",
    "    reimport=False\n",
    ")\n",
    "\n",
    "context.run(schema_importer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-party",
   "metadata": {},
   "source": [
    "### Generate statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-internship",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_gen = tfx.components.StatisticsGen(\n",
    "    instance_name='Statistics_Generation',\n",
    "    examples=train_example_gen.outputs.examples)\n",
    "context.run(statistics_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r {RAW_SCHEMA_DIR}/.ipynb_checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-forest",
   "metadata": {},
   "source": [
    "### Validate statistics against schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-fossil",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_validator = tfx.components.ExampleValidator(\n",
    "    statistics=statistics_gen.outputs.statistics,\n",
    "    schema=schema_importer.outputs.result,\n",
    "    instance_name=\"Data_Validation\"\n",
    ")\n",
    "\n",
    "context.run(example_validator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-patio",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.show(example_validator.outputs.anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-celebrity",
   "metadata": {},
   "source": [
    "## 4. Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-potato",
   "metadata": {},
   "outputs": [],
   "source": [
    "_transform_module_file = 'model_src/preprocessing.py'\n",
    "\n",
    "transform = tfx.components.Transform(\n",
    "    examples=train_example_gen.outputs.examples,\n",
    "    schema=schema_importer.outputs.result,\n",
    "    module_file=_transform_module_file,\n",
    "    splits_config=transform_pb2.SplitsConfig(\n",
    "        analyze=['train'], transform=['train', 'eval']),\n",
    "    instance_name=\"Data_Transformation\"\n",
    ")\n",
    "\n",
    "context.run(transform, enable_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_uri = os.path.join(transform.outputs.transformed_examples.get()[0].uri, \"train/*\")\n",
    "transform_graph_uri = transform.outputs.transform_graph.get()[0].uri\n",
    "\n",
    "tft_output = tft.TFTransformOutput(transform_graph_uri)\n",
    "transform_feature_spec = tft_output.transformed_feature_spec()\n",
    "\n",
    "for input_features, target in data.get_dataset(\n",
    "    train_uri, transform_feature_spec, batch_size=3).take(1):\n",
    "    for key in input_features:\n",
    "        print(f\"{key} ({input_features[key].dtype}): {input_features[key].numpy().tolist()}\")\n",
    "    print(f\"target: {target.numpy().tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-variation",
   "metadata": {},
   "source": [
    "## 5. Custom Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.components.base import executor_spec\n",
    "from tfx.components.trainer import executor as trainer_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-exploration",
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_module_file = 'model_src/runner.py'\n",
    "\n",
    "trainer = tfx.components.Trainer(\n",
    "    custom_executor_spec=executor_spec.ExecutorClassSpec(trainer_executor.GenericExecutor),\n",
    "    module_file=_train_module_file,\n",
    "    transformed_examples=transform.outputs.transformed_examples,\n",
    "    schema=schema_importer.outputs.result,\n",
    "    transform_graph=transform.outputs.transform_graph,\n",
    "    train_args=tfx.proto.trainer_pb2.TrainArgs(num_steps=0),\n",
    "    eval_args=tfx.proto.trainer_pb2.EvalArgs(num_steps=None),\n",
    "    hyperparameters=hyperparams_gen.outputs.hyperparameters,\n",
    "    instance_name='Model_Trainer'\n",
    ")\n",
    "\n",
    "context.run(trainer, enable_cache=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-macedonia",
   "metadata": {},
   "source": [
    "## 6. AutoML Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-ambassador",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_columns = ','.join(['trip_start_timestamp'])\n",
    "\n",
    "automl_trainer = components.automl_trainer(\n",
    "    project=PROJECT,\n",
    "    region=REGION,\n",
    "    dataset_display_name=DATASET_DISPLAYNAME,\n",
    "    model_display_name=AUTOML_MODEL_DISPLAYNAME,\n",
    "    target_column=features.TARGET_FEATURE_NAME,\n",
    "    data_split_column='data_split',\n",
    "    exclude_cloumns=exclude_columns,\n",
    "    schema=schema_importer.outputs.result,\n",
    ")\n",
    "\n",
    "context.run(automl_trainer, enable_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-fourth",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_trainer.outputs.uploaded_model.get()[0].get_string_custom_property('model_uri')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-offer",
   "metadata": {},
   "source": [
    "## 7. Custom Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.components import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-scroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_config = tfma.EvalConfig(\n",
    "    model_specs=[\n",
    "        tfma.ModelSpec(\n",
    "            signature_name='serving_tf_example',\n",
    "            label_key=features.TARGET_FEATURE_NAME,\n",
    "            prediction_key='probabilities')\n",
    "    ],\n",
    "    slicing_specs=[\n",
    "        tfma.SlicingSpec(),\n",
    "    ],\n",
    "    metrics_specs=[\n",
    "        tfma.MetricsSpec(\n",
    "            metrics=[   \n",
    "                tfma.MetricConfig(class_name='ExampleCount'),\n",
    "                tfma.MetricConfig(\n",
    "                    class_name='BinaryAccuracy',\n",
    "                    threshold=tfma.MetricThreshold(\n",
    "                        value_threshold=tfma.GenericValueThreshold(\n",
    "                            lower_bound={'value': 0.8}))),\n",
    "        ])\n",
    "    ])\n",
    "\n",
    "\n",
    "evaluator = Evaluator(\n",
    "    examples=test_example_gen.outputs.examples,\n",
    "    example_splits=['test'],\n",
    "    model=trainer.outputs.model,\n",
    "    eval_config=eval_config,\n",
    "    schema=schema_importer.outputs.result\n",
    ")\n",
    "\n",
    "context.run(evaluator, enable_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = evaluator.outputs.evaluation.get()[0].uri\n",
    "print(\"validation_ok:\", tfma.load_validation_result(evaluation_results).validation_ok)\n",
    "\n",
    "for entry in list(tfma.load_metrics(evaluation_results))[0].metric_keys_and_values:\n",
    "    print(entry.key.name, \":\", round(entry.value.double_value.value, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-covering",
   "metadata": {},
   "source": [
    "## 8. Models Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-china",
   "metadata": {},
   "source": [
    "### Get AutoML evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-miami",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_metric_gen = components.automl_metrics_gen(\n",
    "    project=PROJECT,\n",
    "    region=REGION,\n",
    "    uploaded_model=automl_trainer.outputs.uploaded_model\n",
    ")\n",
    "\n",
    "context.run(automl_metric_gen, enable_cache=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-logic",
   "metadata": {},
   "source": [
    "### Compare the evaluation results of the custom model and the AutoML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = components.custom_model_validator(\n",
    "    model_evaluation=evaluator.outputs.evaluation,\n",
    "    uploaded_model_evaluation=automl_metric_gen.outputs.evaluation,\n",
    ")\n",
    "\n",
    "context.run(validator, enable_cache=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-response",
   "metadata": {},
   "source": [
    "## 9. Model Pushing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-consciousness",
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_model_location = os.path.join(MODEL_REGISTRY, f'{DATASET_DISPLAYNAME}_classifier')\n",
    "\n",
    "push_destination=tfx.proto.pusher_pb2.PushDestination(\n",
    "    filesystem=tfx.proto.pusher_pb2.PushDestination.Filesystem(\n",
    "        base_directory=exported_model_location,\n",
    "    )\n",
    ")\n",
    "\n",
    "pusher = tfx.components.Pusher(\n",
    "    model=trainer.outputs.model,\n",
    "    #model_blessing=evaluator.outputs.blessing,\n",
    "    model_blessing=validator.outputs.blessing,\n",
    "    push_destination=push_destination\n",
    ")\n",
    "\n",
    "context.run(pusher, enable_cache=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-grant",
   "metadata": {},
   "source": [
    "## 10. Model Upload to AI Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-lighting",
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_runtime ='tf2-cpu.2-3'\n",
    "serving_image_uri = f\"gcr.io/cloud-aiplatform/prediction/{serving_runtime}:latest\"\n",
    "\n",
    "aip_model_uploader = components.aip_model_uploader(\n",
    "    project=PROJECT,\n",
    "    region=REGION,\n",
    "    model_display_name=CUSTOM_MODEL_DISPLAYNAME,\n",
    "    pushed_model_location=exported_model_location,\n",
    "    serving_image_uri=serving_image_uri,\n",
    ")\n",
    "\n",
    "context.run(aip_model_uploader, enable_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "aip_model_uploader.outputs.uploaded_model.get()[0].get_string_custom_property('model_uri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-barcelona",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

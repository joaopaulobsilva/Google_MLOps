{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1f43954",
   "metadata": {},
   "source": [
    "# 05 - Continuous Training\n",
    "\n",
    "After testing, compiling, and uploading the pipeline definition to Cloud Storage, the pipeline is executed with respect to a trigger. We use [Cloud Functions](https://cloud.google.com/functions) and [Cloud Pub/Sub](https://cloud.google.com/pubsub) as a triggering mechanism. The triggering can be scheduled using [Cloud Schedular](https://cloud.google.com/scheduler). The trigger source sends a message to a Cloud Pub/Sub topic that the Cloud Function listens to, and then it submits the pipeline to AI Platform Managed Pipelines to be executed.\n",
    "\n",
    "This notebook covers the following steps:\n",
    "1. Create the Cloud Pub/Sub topic.\n",
    "2. Deploy the Cloud Function \n",
    "3. Test triggering a pipeline.\n",
    "4. Extracting pipeline run metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c8ad8b",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b36fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "import tfx\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "print(\"Tensorflow Version:\", tfx.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9d306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'ksalama-cloudml' # Change to your project Id.\n",
    "REGION = 'us-central1'\n",
    "BUCKET = 'ksalama-cloudml-us' # Change to your bucket.\n",
    "\n",
    "VERSION = 'v01'\n",
    "DATASET_DISPLAY_NAME = 'chicago-taxi-tips'\n",
    "MODEL_DISPLAY_NAME = f'{DATASET_DISPLAY_NAME}-classifier-{VERSION}'\n",
    "PIPELINE_NAME = f'{MODEL_DISPLAY_NAME}-train-pipeline'\n",
    "\n",
    "PIPELINES_STORE = f'gs://{BUCKET}/ucaip_demo/compiled_pipelines/'\n",
    "GCS_PIPELINE_FILE_LOCATION = os.path.join(PIPELINES_STORE, f'{PIPELINE_NAME}.json')\n",
    "PUBSUB_TOPIC = f'trigger-{PIPELINE_NAME}'\n",
    "CLOUD_FUNCTION_NAME = f'trigger-{PIPELINE_NAME}-fn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788c8f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls {GCS_PIPELINE_FILE_LOCATION}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f27f19",
   "metadata": {},
   "source": [
    "## 1. Create a Pub/Sub topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcca1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud pubsub topics create {PUBSUB_TOPIC}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9df3b1",
   "metadata": {},
   "source": [
    "## 2. Deploy the Cloud Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5705e443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dash separated pipeline parameter names\n",
    "PARAMETER_NAMES='num_epochs-hidden_units-learning_rate-batch_size'\n",
    "\n",
    "ENV_VARS=f\"\"\"\\\n",
    "PROJECT={PROJECT},\\\n",
    "REGION={REGION},\\\n",
    "GCS_PIPELINE_FILE_LOCATION={GCS_PIPELINE_FILE_LOCATION},\\\n",
    "PARAMETER_NAMES={PARAMETER_NAMES}\n",
    "\"\"\"\n",
    "\n",
    "!echo {ENV_VARS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8717b5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r src/pipeline_triggering/.ipynb_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ec0cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud functions deploy {CLOUD_FUNCTION_NAME} \\\n",
    "    --region={REGION} \\\n",
    "    --trigger-topic={PUBSUB_TOPIC} \\\n",
    "    --runtime=python37 \\\n",
    "    --source=src/pipeline_triggering\\\n",
    "    --entry-point=trigger_pipeline\\\n",
    "    --stage-bucket={BUCKET}\\\n",
    "    --update-env-vars={ENV_VARS}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ec4a1c",
   "metadata": {},
   "source": [
    "## 3. Test Triggering the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02635023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import pubsub\n",
    "\n",
    "publish_client = pubsub.PublisherClient()\n",
    "topic = f'projects/{PROJECT}/topics/{PUBSUB_TOPIC}'\n",
    "data = {\n",
    "    'source_uri': 'pubsub/function/pipline',\n",
    "    'num_epochs': 7,\n",
    "    'learning_rate': 0.0015,\n",
    "    'batch_size': 512,\n",
    "    'hidden_units': '256,126'\n",
    "}\n",
    "message = json.dumps(data)\n",
    "\n",
    "_ = publish_client.publish(topic, message.encode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28229745",
   "metadata": {},
   "source": [
    "## 4. Extracting Pipeline Runs Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e52cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.vertex_utils import VertexClient\n",
    "vertex_client = VertexClient(PROJECT, REGION)\n",
    "vertex_client.get_pipeline_metadata_df(pipeline=PIPELINE_NAME)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m71",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m71"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

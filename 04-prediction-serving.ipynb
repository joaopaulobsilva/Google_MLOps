{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "religious-interest",
   "metadata": {},
   "source": [
    "# 03 - Model Serving\n",
    "\n",
    "The purpose of the notebook is to show how to serve both AutoML Tables and Custom models for online and batch prediction.\n",
    "The notebook covers the following tasks:\n",
    "1. Creating an AI Platform Endpoint\n",
    "2. Deploy thethe custom modesl to the endpoint.\n",
    "3. Test the endpoints for online prediction.\n",
    "4. Use the uploaded custom model for batch prediciton."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-nightlife",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-matter",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'ksalama-cloudml'  # Change to your project Id.\n",
    "REGION = 'us-central1'\n",
    "BUCKET = 'ksalama-cloudml-us' # Change to your bucket.\n",
    "\n",
    "BQ_DATASET_NAME = 'playground_us' # Change to your serving BigQuery dataset name.\n",
    "BQ_TABLE_NAME = 'chicago_taxitrips_prep' # Change to your serving BigQuery table name.\n",
    "MODEL_ENDPOINT_DISPLAY_NAME = 'chicago_taxi_tips_classifier'\n",
    "MODEL_DISPLAY_NAME = 'chicago_taxi_tips_classifier_custom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.ucaip_utils import AIPUtils\n",
    "aip_utils = AIPUtils(PROJECT, REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-representation",
   "metadata": {},
   "source": [
    "## 1. Create AI Platform Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = aip_utils.create_endpoint(MODEL_ENDPOINT_DISPLAY_NAME)\n",
    "response.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-basketball",
   "metadata": {},
   "source": [
    "## 2. Deploy AI Platform Model to Endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-russian",
   "metadata": {},
   "outputs": [],
   "source": [
    "dedicated_serving_resources_spec = { \n",
    "    'machine_spec': {\n",
    "        'machine_type': 'n1-standard-2',\n",
    "        #'accelerator_count': 1,\n",
    "        #'accelerator_type': 'NVIDIA_TESLA_T4'\n",
    "    },\n",
    "    'min_replica_count': 1,\n",
    "    'max_replica_count': 5\n",
    "}\n",
    "\n",
    "response = aip_utils.deploy_model(\n",
    "    model_display_name=MODEL_DISPLAY_NAME,\n",
    "    endpoint_display_name=MODEL_ENDPOINT_DISPLAY_NAME,\n",
    "    dedicated_serving_resources_spec=dedicated_serving_resources_spec,\n",
    "    traffic_split={\"0\": 100}\n",
    ")\n",
    "\n",
    "response.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-calendar",
   "metadata": {},
   "source": [
    "## 3. Making Online Predicitons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-closure",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = aip_utils.get_endpoint_by_display_name(\n",
    "    MODEL_ENDPOINT_DISPLAY_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-express",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instance = {\n",
    "    \"dropoff_grid\": [\"POINT(-87.6 41.9)\"],\n",
    "    \"euclidean\": [2064.2696],\n",
    "    \"loc_cross\": [\"\"],\n",
    "    \"payment_type\": [\"Credit Card\"],\n",
    "    \"pickup_grid\": [\"POINT(-87.6 41.9)\"],\n",
    "    \"trip_miles\": [1.37],\n",
    "    \"trip_day\": [12],\n",
    "    \"trip_hour\": [16],\n",
    "    \"trip_month\": [2],\n",
    "    \"trip_day_of_week\": [4],\n",
    "    \"trip_seconds\": [555],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-overhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    response = aip_utils.predict_tabular_classifier(\n",
    "        endpoint.name,\n",
    "        test_instance)\n",
    "    \n",
    "    print(f\"Model {response.deployed_model_id}) responded:\")\n",
    "    for prediction in response.predictions:\n",
    "        print(dict(prediction))\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-diary",
   "metadata": {},
   "source": [
    "## 5. Batch Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-issue",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKSPACE = f\"gs://{BUCKET}/ucaip_demo/chicago_taxi\"\n",
    "SERVING_DATA_DIR = os.path.join(WORKSPACE, 'serving_data')\n",
    "SERVING_INPUT_DATA_DIR = os.path.join(SERVING_DATA_DIR, 'input_data')\n",
    "SERVING_OUTPUT_DATA_DIR = os.path.join(SERVING_DATA_DIR, 'output_predictions')\n",
    "\n",
    "RAW_SCHEMA_LOCATION = 'src/raw_schema/schema.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.io.gfile.exists(SERVING_DATA_DIR):\n",
    "    print(\"Removing previous serving data...\")\n",
    "    tf.io.gfile.rmtree(SERVING_DATA_DIR)\n",
    "print(\"Creating preprocessing serving data directory...\")\n",
    "tf.io.gfile.mkdir(SERVING_DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-policy",
   "metadata": {},
   "source": [
    "### Extract serving data to Cloud Storage as TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-charles",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import datasource_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SPLIT = 'TEST'\n",
    "LIMIT = 10000\n",
    "\n",
    "raw_data_query = datasource_utils.get_serving_source_query(\n",
    "    bq_dataset_name=BQ_DATASET_NAME, \n",
    "    bq_table_name=BQ_TABLE_NAME,\n",
    "    limit=LIMIT\n",
    ")\n",
    "\n",
    "print(raw_data_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-passenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    #'runner': 'DataflowRunner',\n",
    "    'raw_schema_location': RAW_SCHEMA_LOCATION,\n",
    "    'raw_data_query': raw_data_query,\n",
    "    'exported_data_prefix': os.path.join(SERVING_INPUT_DATA_DIR, \"data-\"),\n",
    "    'temporary_dir': os.path.join(WORKSPACE, 'tmp'),\n",
    "    'gcs_location': os.path.join(WORKSPACE, 'bq_tmp'),\n",
    "    'project': PROJECT,\n",
    "    'region': REGION,\n",
    "    'setup_file': './setup.py'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing import etl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "print(\"Data extraction started...\")\n",
    "etl.run_extract_pipeline(args)\n",
    "print(\"Data extraction completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls {SERVING_INPUT_DATA_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-leader",
   "metadata": {},
   "source": [
    "### Prepare the batch prediction job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-hotel",
   "metadata": {},
   "outputs": [],
   "source": [
    "dedicated_resources =  {\n",
    "    \"machine_spec\": {\n",
    "        \"machine_type\": 'n1-standard-2',\n",
    "        #'accelerator_count': 1,\n",
    "        #'accelerator_type': 'NVIDIA_TESLA_T4'\n",
    "    },\n",
    "    \"starting_replica_count\": 1,\n",
    "    \"max_replica_count\": 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-address",
   "metadata": {},
   "source": [
    "### Submit the batch prediction job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_prediction_job = aip_utils.submit_batch_prediction_job(\n",
    "    model_display_name=MODEL_DISPLAY_NAME, \n",
    "    gcs_data_uri_pattern=SERVING_INPUT_DATA_DIR + '/*.jsonl', \n",
    "    gcs_output_uri=SERVING_OUTPUT_DATA_DIR,\n",
    "    dedicated_resources=dedicated_resources,\n",
    "    instances_format='jsonl',\n",
    "    predictions_format='jsonl'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-shaft",
   "metadata": {},
   "source": [
    "### Monitor job state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-perth",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    response = aip_utils.get_batch_prediction_job_by_uri(batch_prediction_job.name)\n",
    "    if response.state.name == 'JOB_STATE_SUCCEEDED':\n",
    "        print(\"Batch prediction completed. - Training Time:\", response.update_time - response.create_time)\n",
    "        break\n",
    "    elif response.state.name == 'JOB_STATE_FAILED':\n",
    "        print(\"Batch prediction failed!\")\n",
    "        break\n",
    "    else:\n",
    "        print(f\"Batch prediction state is: {response.state.name}.\")\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls {SERVING_OUTPUT_DATA_DIR}"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e51d941",
   "metadata": {},
   "source": [
    "# 01 - Data Analysis and Preparation\n",
    "\n",
    "This notebook covers the following tasks:\n",
    "\n",
    "1. Perform `Exploratory Data Analysis` and `Visualization`.\n",
    "2. Prepare the data for the ML task in `BigQuery`.\n",
    "3. Generate and fix the raw data schema.\n",
    "4. Create a `Vertex Dataset` resource (i.e., managed dataset).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79da7a20",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The [Chicago Taxi Trips](https://pantheon.corp.google.com/marketplace/details/city-of-chicago-public-data/chicago-taxi-trips) dataset is one of [public datasets hosted with BigQuery](https://cloud.google.com/bigquery/public-data/), which includes taxi trips from 2013 to the present, reported to the City of Chicago in its role as a regulatory agency. The `taxi_trips` table size is 70.72 GB and includes more than 195 million records. The dataset includes information about the trips, like pickup and dropoff datetime and location, passengers count, miles travelled, and trip toll. \n",
    "\n",
    "The ML task is to predict whether a given trip will result in a tip > 20%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282c2d25",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Builtin Jupyter command to reload all Python imported modules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453f2cd6",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Install the latest version of Vertex SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9effc5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "# Google Cloud Notebook\n",
    "if os.path.exists(\"/opt/deeplearning/metadata/env_version\"):\n",
    "    USER_FLAG = '--user'\n",
    "else:\n",
    "    USER_FLAG = ''\n",
    "\n",
    "! pip3 install --upgrade google-cloud-aiplatform $USER_FLAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1565cba",
   "metadata": {},
   "source": [
    "Install the latest GA version of *google-cloud-storage* library as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561d8221",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install -U google-cloud-storage $USER_FLAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ea70d0",
   "metadata": {},
   "source": [
    "Install deep learning dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af18657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install -U tfx==0.30.0 $USER_FLAG\n",
    "! pip3 install -r requirements.txt $USER_FLAG\n",
    "! pip3 install --upgrade google-cloud-bigquery-storage $USER_FLAG\n",
    "! pip3 install --upgrade google-cloud-bigquery $USER_FLAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5107b077",
   "metadata": {},
   "source": [
    "### Restart the kernel\n",
    "\n",
    "Once you've installed the Vertex SDK and Google *cloud-storage*, you need to restart the notebook kernel so it can find the packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbf382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b9a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea28836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_data_validation as tfdv\n",
    "from google.cloud import bigquery\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud import aiplatform_v1beta1 as vertex_ai_beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f043bc8a",
   "metadata": {},
   "source": [
    "### Setup your Google Cloud project\n",
    "\n",
    "Enter your project ID in the cell below. Then run the  cell to make sure the\n",
    "Cloud SDK uses the right project for all the commands in this notebook.\n",
    "\n",
    "**Note**: Jupyter runs lines prefixed with `!` as shell commands, and it interpolates Python variables prefixed with `$` into these commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6982183",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05749188",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID:\", PROJECT_ID)\n",
    "\n",
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001b54c3",
   "metadata": {},
   "source": [
    "#### Region\n",
    "\n",
    "You can also change the `REGION` variable, which is used for operations\n",
    "throughout the rest of this notebook.  Below are regions supported for Vertex. We recommend that you choose the region closest to you.\n",
    "\n",
    "- Americas: `us-central1`\n",
    "- Europe: `europe-west4`\n",
    "- Asia Pacific: `asia-east1`\n",
    "\n",
    "You may not use a multi-regional bucket for training with Vertex. Not all regions provide support for all Vertex services. For the latest support per region, see the [Vertex locations documentation](https://cloud.google.com/ai-platform-unified/docs/general/locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3828e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'  #@param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d98988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33321a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BQ_DATASET_NAME = 'playground_us' # Change to your BQ datasent name.\n",
    "BQ_TABLE_NAME = 'chicago_taxitrips_prep'\n",
    "BQ_LOCATION = 'US'\n",
    "\n",
    "RAW_SCHEMA_DIR = 'src/raw_schema'\n",
    "\n",
    "DATASET_DISPLAY_NAME = 'chicago_taxi_tips'\n",
    "BQ_URI = f\"bq://{PROJECT_ID}.{BQ_DATASET_NAME}.{BQ_TABLE_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7eb256",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bq --location=US mk -d \\\n",
    "$PROJECT_ID:$BQ_DATASET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0e43e2",
   "metadata": {},
   "source": [
    "## 1. Explore the data in BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8924cc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_script = '''\n",
    "SELECT \n",
    "    CAST(EXTRACT(DAYOFWEEK FROM trip_start_timestamp) AS string) AS trip_dayofweek, \n",
    "    FORMAT_DATE('%A',cast(trip_start_timestamp as date)) AS trip_dayname,\n",
    "    COUNT(*) as trip_count,\n",
    "FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "WHERE\n",
    "    EXTRACT(YEAR FROM trip_start_timestamp) = 2015 \n",
    "GROUP BY\n",
    "    trip_dayofweek,\n",
    "    trip_dayname\n",
    "ORDER BY\n",
    "    trip_dayofweek\n",
    ";\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e888b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_client = bigquery.Client(project=PROJECT_ID, location=BQ_LOCATION)\n",
    "job = bq_client.query(sql_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3f2106",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = job.result()\n",
    "data=[]\n",
    "for row in result:\n",
    "    data.append(row.values())\n",
    "    \n",
    "from pandas import DataFrame\n",
    "df = DataFrame(data, columns=['id', 'trip_dayname', 'trip_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69879174",
   "metadata": {},
   "source": [
    "Display data item counts per day of the week in table format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ce52f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c9594f",
   "metadata": {},
   "source": [
    "Display data item counts per day of the week as a bar graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cef1458",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='bar', x='trip_dayname', y='trip_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cedfe2",
   "metadata": {},
   "source": [
    "## 2. Create data for the ML task\n",
    "\n",
    "We add a `ML_use` column for pre-splitting the data, where 80% of the datsa items are set to `UNASSIGNED` while the other 20% is set to `TEST`.\n",
    "\n",
    "This column is used during training (custom and AutoML) to split the dataset for training and test.\n",
    "\n",
    "In the training phase, the `UNASSIGNED` are split into `train` and `eval`. The `TEST` split is will be used for the final model validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499b4a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use maximum of 1M data items\n",
    "sample_size = 1000000\n",
    "\n",
    "# Limit data items to the year 2020\n",
    "year = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd1fc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_script = '''\n",
    "CREATE OR REPLACE TABLE `@PROJECT_ID.@DATASET.@TABLE` \n",
    "AS (\n",
    "    WITH\n",
    "      taxitrips AS (\n",
    "      SELECT\n",
    "        trip_start_timestamp,\n",
    "        trip_seconds,\n",
    "        trip_miles,\n",
    "        payment_type,\n",
    "        pickup_longitude,\n",
    "        pickup_latitude,\n",
    "        dropoff_longitude,\n",
    "        dropoff_latitude,\n",
    "        tips,\n",
    "        fare\n",
    "      FROM\n",
    "        `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "      WHERE 1=1 \n",
    "      AND pickup_longitude IS NOT NULL\n",
    "      AND pickup_latitude IS NOT NULL\n",
    "      AND dropoff_longitude IS NOT NULL\n",
    "      AND dropoff_latitude IS NOT NULL\n",
    "      AND trip_miles > 0\n",
    "      AND trip_seconds > 0\n",
    "      AND fare > 0\n",
    "      AND EXTRACT(YEAR FROM trip_start_timestamp) = @YEAR\n",
    "    )\n",
    "\n",
    "    SELECT\n",
    "      trip_start_timestamp,\n",
    "      EXTRACT(MONTH from trip_start_timestamp) as trip_month,\n",
    "      EXTRACT(DAY from trip_start_timestamp) as trip_day,\n",
    "      EXTRACT(DAYOFWEEK from trip_start_timestamp) as trip_day_of_week,\n",
    "      EXTRACT(HOUR from trip_start_timestamp) as trip_hour,\n",
    "      trip_seconds,\n",
    "      trip_miles,\n",
    "      payment_type,\n",
    "      ST_AsText(\n",
    "          ST_SnapToGrid(ST_GeogPoint(pickup_longitude, pickup_latitude), 0.1)\n",
    "      ) AS pickup_grid,\n",
    "      ST_AsText(\n",
    "          ST_SnapToGrid(ST_GeogPoint(dropoff_longitude, dropoff_latitude), 0.1)\n",
    "      ) AS dropoff_grid,\n",
    "      ST_Distance(\n",
    "          ST_GeogPoint(pickup_longitude, pickup_latitude), \n",
    "          ST_GeogPoint(dropoff_longitude, dropoff_latitude)\n",
    "      ) AS euclidean,\n",
    "      CONCAT(\n",
    "          ST_AsText(ST_SnapToGrid(ST_GeogPoint(pickup_longitude,\n",
    "              pickup_latitude), 0.1)), \n",
    "          ST_AsText(ST_SnapToGrid(ST_GeogPoint(dropoff_longitude,\n",
    "              dropoff_latitude), 0.1))\n",
    "      ) AS loc_cross,\n",
    "      IF((tips/fare >= 0.2), 1, 0) AS tip_bin,\n",
    "      IF(RAND() <= 0.8, 'UNASSIGNED', 'TEST') AS ML_use\n",
    "    FROM\n",
    "      taxitrips\n",
    "    LIMIT @LIMIT\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82036a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_script = sql_script.replace(\n",
    "    '@PROJECT_ID', PROJECT_ID).replace(\n",
    "    '@DATASET', BQ_DATASET_NAME).replace(\n",
    "    '@TABLE', BQ_TABLE_NAME).replace(\n",
    "    '@YEAR', str(year)).replace(\n",
    "    '@LIMIT', str(sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6e8736",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sql_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae085ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_client = bigquery.Client(project=PROJECT_ID, location=BQ_LOCATION)\n",
    "job = bq_client.query(sql_script)\n",
    "job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfede14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_script = '''\n",
    "SELECT ML_use, COUNT(*)\n",
    "FROM PROJECT_ID.playground_us.chicago_taxitrips_prep\n",
    "GROUP BY ML_use\n",
    "'''.replace('PROJECT_ID', PROJECT_ID)\n",
    "\n",
    "print(sql_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78918bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = bq_client.query(sql_script)\n",
    "result = job.result()\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481f4558",
   "metadata": {},
   "source": [
    "### Load a sample data to a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b158590",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_script = '''\n",
    "SELECT * EXCEPT (trip_start_timestamp, ML_use)\n",
    "FROM PROJECT_ID.playground_us.chicago_taxitrips_prep\n",
    "'''.replace('PROJECT_ID', PROJECT_ID)\n",
    "\n",
    "print(sql_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c294a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = bq_client.query(sql_script)\n",
    "sample_data = job.result().to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaae0b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe9bb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data.tip_bin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589db6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data.euclidean.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab9604a",
   "metadata": {},
   "source": [
    "## 3. Generate the raw data schema\n",
    "\n",
    "The raw data schema will be used in:\n",
    "1. Defining the input columns for the `AutoML Tabular` model.\n",
    "2. Indentifying the raw data types and shapes in the feature transformations.\n",
    "3. Create the serving input signature for the custom model.\n",
    "4. Validating the new raw training data in the TFX pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d2b76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = tfdv.generate_statistics_from_dataframe(\n",
    "    dataframe=sample_data,\n",
    "    stats_options=tfdv.StatsOptions(\n",
    "        label_feature='tip_bin',\n",
    "        weight_feature=None,\n",
    "        sample_rate=1,\n",
    "        num_top_values=50\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fe44a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdv.visualize_statistics(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a1f16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = tfdv.infer_schema(statistics=stats)\n",
    "tfdv.display_schema(schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06a2a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_schema_location = os.path.join(RAW_SCHEMA_DIR, 'schema.pbtxt')\n",
    "tfdv.write_schema_text(schema, raw_schema_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3655245",
   "metadata": {},
   "source": [
    "## 4. Create `Vertex Dataset` resource"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac54cf76",
   "metadata": {},
   "source": [
    "### Create `Dataset` resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfcf627",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = vertex_ai.TabularDataset.create(\n",
    "            display_name=DATASET_DISPLAY_NAME, bq_source=BQ_URI)\n",
    "\n",
    "print(dataset.gca_resource)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfae9716",
   "metadata": {},
   "source": [
    "### Get `Dataset` resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257cc5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = vertex_ai.TabularDataset.list(filter=f\"display_name={DATASET_DISPLAY_NAME}\")\n",
    "dataset = datasets[0]\n",
    "dataset.resource_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d77eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.gca_resource.metadata['inputConfig']['bigquerySource']['uri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a510d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.m71",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m71"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

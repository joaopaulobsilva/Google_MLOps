{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "894b08b2",
   "metadata": {},
   "source": [
    "# 07 - Serving predictions\n",
    "\n",
    "The purpose of the notebook is to show how to use the deployed model for online and batch prediction.\n",
    "The notebook covers the following tasks:\n",
    "\n",
    "1. Test the `Endpoint` resource for online prediction.\n",
    "2. Use the custom model uploaded as a `Model` resource for batch prediciton.\n",
    "3. Run a the batch prediction pipeline using `Vertex Pipelines`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd283bf6",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664a735b",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d52235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eae33b",
   "metadata": {},
   "source": [
    "### Setup Google Cloud project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6345ceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = '[your-project-id]' # Change to your project id.\n",
    "REGION = 'us-central1' # Change to your region.\n",
    "BUCKET = 'gs://[your-bucket-name]'  # Change to your bucket name.\n",
    "\n",
    "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    \n",
    "if BUCKET == \"\" or BUCKET is None or BUCKET == \"gs://[your-bucket-name]\":\n",
    "    # Set your bucket name using your GCP project id\n",
    "    BUCKET = 'gs://' + PROJECT_ID + '-mlops'\n",
    "    # Try to create the bucket if it doesn'exists\n",
    "    ! gsutil mb -l $REGION $BUCKET\n",
    "    print(\"\")\n",
    "    \n",
    "print(\"Project ID:\", PROJECT_ID)\n",
    "print(\"Region:\", REGION)\n",
    "print(\"Bucket name:\", BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db73c786",
   "metadata": {},
   "source": [
    "### Set configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a388ac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 'v1'\n",
    "DATASET_DISPLAY_NAME = 'chicago-taxi-tips'\n",
    "MODEL_DISPLAY_NAME = f'{DATASET_DISPLAY_NAME}-classifier-{VERSION}'\n",
    "ENDPOINT_DISPLAY_NAME = f'{DATASET_DISPLAY_NAME}-classifier'\n",
    "\n",
    "SERVE_BQ_DATASET_NAME = 'playground_us' # Change to your serving BigQuery dataset name.\n",
    "SERVE_BQ_TABLE_NAME = 'chicago_taxitrips_prep' # Change to your serving BigQuery table name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974493ae",
   "metadata": {},
   "source": [
    "## 1. Making an online prediciton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b95ef03",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    staging_bucket=BUCKET\n",
    ")\n",
    "\n",
    "endpoint_name = vertex_ai.Endpoint.list(\n",
    "    filter=f'display_name={ENDPOINT_DISPLAY_NAME}', \n",
    "    order_by=\"update_time\")[-1].gca_resource.name\n",
    "\n",
    "endpoint = vertex_ai.Endpoint(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3a9b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instances = [  \n",
    "    {\n",
    "        \"dropoff_grid\": [\"POINT(-87.6 41.9)\"],\n",
    "        \"euclidean\": [2064.2696],\n",
    "        \"loc_cross\": [\"\"],\n",
    "        \"payment_type\": [\"Credit Card\"],\n",
    "        \"pickup_grid\": [\"POINT(-87.6 41.9)\"],\n",
    "        \"trip_miles\": [1.37],\n",
    "        \"trip_day\": [12],\n",
    "        \"trip_hour\": [16],\n",
    "        \"trip_month\": [2],\n",
    "        \"trip_day_of_week\": [4],\n",
    "        \"trip_seconds\": [555]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b65dc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = endpoint.predict(test_instances).predictions\n",
    "\n",
    "for prediction in predictions:\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c0b4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO {for Khalid, get error saying model does not support explanations}\n",
    "\n",
    "explanations = endpoint.explain(test_instances).explanations\n",
    "\n",
    "for explanation in explanations:\n",
    "    print(explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c48ab7",
   "metadata": {},
   "source": [
    "## 2. Make a batch prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6311dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKSPACE = f\"{BUCKET}/{DATASET_DISPLAY_NAME}/\"\n",
    "SERVING_DATA_DIR = os.path.join(WORKSPACE, 'serving_data')\n",
    "SERVING_INPUT_DATA_DIR = os.path.join(SERVING_DATA_DIR, 'input_data')\n",
    "SERVING_OUTPUT_DATA_DIR = os.path.join(SERVING_DATA_DIR, 'output_predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fc7b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.io.gfile.exists(SERVING_DATA_DIR):\n",
    "    print(\"Removing previous serving data...\")\n",
    "    tf.io.gfile.rmtree(SERVING_DATA_DIR)\n",
    "print(\"Creating serving data directory...\")\n",
    "tf.io.gfile.mkdir(SERVING_DATA_DIR)\n",
    "print(\"Serving data directory is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95b6751",
   "metadata": {},
   "source": [
    "### Extract serving data to Cloud Storage as JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80ab898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.common import datasource_utils\n",
    "from src.preprocessing import etl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72380df",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMIT = 10000\n",
    "\n",
    "sql_query = datasource_utils.get_serving_source_query(\n",
    "    bq_dataset_name=SERVE_BQ_DATASET_NAME, \n",
    "    bq_table_name=SERVE_BQ_TABLE_NAME,\n",
    "    limit=LIMIT\n",
    ")\n",
    "\n",
    "print(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9556853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    #'runner': 'DataflowRunner',\n",
    "    'sql_query': sql_query,\n",
    "    'exported_data_prefix': os.path.join(SERVING_INPUT_DATA_DIR, \"data-\"),\n",
    "    'temporary_dir': os.path.join(WORKSPACE, 'tmp'),\n",
    "    'gcs_location': os.path.join(WORKSPACE, 'bq_tmp'),\n",
    "    'project': PROJECT_ID,\n",
    "    'region': REGION,\n",
    "    'setup_file': './setup.py'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1a5ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "print(\"Data extraction started...\")\n",
    "etl.run_extract_pipeline(args)\n",
    "print(\"Data extraction completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00abc2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls {SERVING_INPUT_DATA_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86441fac",
   "metadata": {},
   "source": [
    "### Submit the batch prediction job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb96118",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name =  vertex_ai.Model.list(\n",
    "    filter=f'display_name={MODEL_DISPLAY_NAME}',\n",
    "    order_by=\"update_time\")[-1].gca_resource.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b0d29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_resources =  {\n",
    "    \"machine_type\": 'n1-standard-2',\n",
    "    #'accelerator_count': 1,\n",
    "    #'accelerator_type': 'NVIDIA_TESLA_T4'\n",
    "    \"starting_replica_count\": 1,\n",
    "    \"max_replica_count\": 10,\n",
    "}\n",
    "\n",
    "job_display_name = f\"{MODEL_DISPLAY_NAME}-prediction-job-{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "\n",
    "vertex_ai.BatchPredictionJob.create(\n",
    "    job_display_name=job_display_name,\n",
    "    model_name=model_name,\n",
    "    gcs_source=SERVING_INPUT_DATA_DIR + '/*.jsonl',\n",
    "    gcs_destination_prefix=SERVING_OUTPUT_DATA_DIR,\n",
    "    instances_format='jsonl',\n",
    "    predictions_format='jsonl',\n",
    "    sync=True,\n",
    "    **job_resources,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441d5b37",
   "metadata": {},
   "source": [
    "## 3. Run the batch prediction pipeline using `Vertex Pipelines`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c4b7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKSPACE = f\"{BUCKET}/{DATASET_DISPLAY_NAME}/\"\n",
    "MLMD_SQLLITE = 'mlmd.sqllite'\n",
    "ARTIFACT_STORE = os.path.join(WORKSPACE, 'tfx_artifacts')\n",
    "PIPELINE_NAME = f'{MODEL_DISPLAY_NAME}-predict-pipeline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f58c1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PROJECT\"] = PROJECT_ID\n",
    "os.environ[\"REGION\"] = REGION\n",
    "os.environ[\"MODEL_DISPLAY_NAME\"] = MODEL_DISPLAY_NAME\n",
    "os.environ[\"PIPELINE_NAME\"] = PIPELINE_NAME\n",
    "os.environ[\"ARTIFACT_STORE_URI\"] = ARTIFACT_STORE\n",
    "os.environ[\"BATCH_PREDICTION_BQ_DATASET_NAME\"] = SERVE_BQ_DATASET_NAME\n",
    "os.environ[\"BATCH_PREDICTION_BQ_TABLE_NAME\"] = SERVE_BQ_TABLE_NAME\n",
    "os.environ[\"SERVE_LIMIT\"] = \"1000\"\n",
    "os.environ[\"BEAM_RUNNER\"] = \"DirectRunner\"\n",
    "os.environ[\"TFX_IMAGE_URI\"] = f\"gcr.io/{PROJECT_ID}/{DATASET_DISPLAY_NAME}:{VERSION}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7febdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from src.tfx_pipelines import config\n",
    "importlib.reload(config)\n",
    "\n",
    "for key, value in config.__dict__.items():\n",
    "    if key.isupper(): print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9253ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tfx_pipelines import runner\n",
    "\n",
    "pipeline_definition_file = f'{config.PIPELINE_NAME}.json'\n",
    "pipeline_definition = runner.compile_prediction_pipeline(pipeline_definition_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc4190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2.google.client import AIPlatformClient\n",
    "\n",
    "pipeline_client = AIPlatformClient(\n",
    "    project_id=PROJECT_ID, region=REGION)\n",
    "                 \n",
    "pipeline_client.create_run_from_job_spec(\n",
    "    job_spec_path=pipeline_definition_file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a533a4c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.m71",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m71"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

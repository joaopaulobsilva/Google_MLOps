{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "proper-packet",
   "metadata": {},
   "source": [
    "# 07 - Prediction Serving\n",
    "\n",
    "The purpose of the notebook is to show how to use the deployed model for online and batch prediction.\n",
    "The notebook covers the following tasks:\n",
    "1. Test the endpoints for online prediction.\n",
    "2. Use the uploaded custom model for batch prediciton.\n",
    "3. Run a the batch prediction pipeline using Vertex AI pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-notification",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-stream",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'ksalama-cloudml'  # Change to your project Id.\n",
    "REGION = 'us-central1'\n",
    "BUCKET = 'ksalama-cloudml-us' # Change to your bucket.\n",
    "\n",
    "SERVE_BQ_DATASET_NAME = 'playground_us' # Change to your serving BigQuery dataset name.\n",
    "SERVE_BQ_TABLE_NAME = 'chicago_taxitrips_prep' # Change to your serving BigQuery table name.\n",
    "MODEL_DISPLAY_NAME = 'chicago-taxi-tips-classifier-v1'\n",
    "ENDPOINT_DISPLAY_NAME = 'chicago-taxi-tips-classifier'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-baking",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.vertex_utils import VertexClient\n",
    "vertex_client = VertexClient(PROJECT, REGION, BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-blood",
   "metadata": {},
   "source": [
    "## 1. Making Online Predicitons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instances = [  \n",
    "    {\n",
    "        \"dropoff_grid\": [\"POINT(-87.6 41.9)\"],\n",
    "        \"euclidean\": [2064.2696],\n",
    "        \"loc_cross\": [\"\"],\n",
    "        \"payment_type\": [\"Credit Card\"],\n",
    "        \"pickup_grid\": [\"POINT(-87.6 41.9)\"],\n",
    "        \"trip_miles\": [1.37],\n",
    "        \"trip_day\": [12],\n",
    "        \"trip_hour\": [16],\n",
    "        \"trip_month\": [2],\n",
    "        \"trip_day_of_week\": [4],\n",
    "        \"trip_seconds\": [555]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = vertex_client.predict(\n",
    "    ENDPOINT_DISPLAY_NAME,\n",
    "    test_instances).predictions\n",
    "\n",
    "for prediction in predictions:\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-grammar",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainations = vertex_client.explain(\n",
    "    ENDPOINT_DISPLAY_NAME,\n",
    "    test_instances).predictions\n",
    "\n",
    "for explanation in explanations:\n",
    "    print(explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-wyoming",
   "metadata": {},
   "source": [
    "## 2. Batch Precition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKSPACE = f\"gs://{BUCKET}/ucaip_demo/\"\n",
    "SERVING_DATA_DIR = os.path.join(WORKSPACE, 'serving_data')\n",
    "SERVING_INPUT_DATA_DIR = os.path.join(SERVING_DATA_DIR, 'input_data')\n",
    "SERVING_OUTPUT_DATA_DIR = os.path.join(SERVING_DATA_DIR, 'output_predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-learning",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.io.gfile.exists(SERVING_DATA_DIR):\n",
    "    print(\"Removing previous serving data...\")\n",
    "    tf.io.gfile.rmtree(SERVING_DATA_DIR)\n",
    "print(\"Creating preprocessing serving data directory...\")\n",
    "tf.io.gfile.mkdir(SERVING_DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-spray",
   "metadata": {},
   "source": [
    "### Extract serving data to Cloud Storage as JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-actor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import datasource_utils\n",
    "from src.preprocessing import etl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-premises",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SPLIT = 'TEST'\n",
    "LIMIT = 10000\n",
    "\n",
    "sql_query = datasource_utils.get_serving_source_query(\n",
    "    bq_dataset_name=BQ_DATASET_NAME, \n",
    "    bq_table_name=BQ_TABLE_NAME,\n",
    "    limit=LIMIT\n",
    ")\n",
    "\n",
    "print(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-income",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'runner': 'DataflowRunner',\n",
    "    'raw_schema_location': RAW_SCHEMA_LOCATION,\n",
    "    'raw_data_query': raw_data_query,\n",
    "    'exported_data_prefix': os.path.join(SERVING_INPUT_DATA_DIR, \"data-\"),\n",
    "    'temporary_dir': os.path.join(WORKSPACE, 'tmp'),\n",
    "    'gcs_location': os.path.join(WORKSPACE, 'bq_tmp'),\n",
    "    'project': PROJECT,\n",
    "    'region': REGION,\n",
    "    'setup_file': './setup.py'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-beijing",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "print(\"Data extraction started...\")\n",
    "etl.run_extract_pipeline(args)\n",
    "print(\"Data extraction completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls {SERVING_INPUT_DATA_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-majority",
   "metadata": {},
   "source": [
    "### Submit the batch prediction job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-bearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_resources =  {\n",
    "    \"machine_type\": 'n1-standard-2',\n",
    "    #'accelerator_count': 1,\n",
    "    #'accelerator_type': 'NVIDIA_TESLA_T4'\n",
    "    \"starting_replica_count\": 1,\n",
    "    \"max_replica_count\": 10,\n",
    "}\n",
    "\n",
    "batch_prediction_job = vertex_client.submit_batch_prediction_job(\n",
    "    model_display_name=MODEL_DISPLAY_NAME, \n",
    "    gcs_source_pattern=SERVING_INPUT_DATA_DIR + '/*.jsonl', \n",
    "    gcs_destination_prefix=SERVING_OUTPUT_DATA_DIR,\n",
    "    instances_format='jsonl',\n",
    "    predictions_format='jsonl',\n",
    "    other_configurations=job_resources,\n",
    "    sync=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-attribute",
   "metadata": {},
   "source": [
    "## 3. Run the Batch Prediction Pipeline using Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-jason",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKSPACE = f\"gs://{BUCKET}/ucaip_demo/\"\n",
    "MLMD_SQLLITE = 'mlmd.sqllite'\n",
    "ARTIFACT_STORE = os.path.join(WORKSPACE, 'tfx_artifacts')\n",
    "PIPELINE_NAME = f'{MODEL_DISPLAY_NAME}_predict_pipeline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-cleveland",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"REGION\"] = REGION\n",
    "os.environ[\"MODEL_DISPLAY_NAME\"] = MODEL_DISPLAY_NAME\n",
    "os.environ[\"PIPELINE_NAME\"] = PIPELINE_NAME\n",
    "os.environ[\"ARTIFACT_STORE_URI\"] = ARTIFACT_STORE\n",
    "os.environ[\"BATCH_PREDICTION_BQ_DATASET_NAME\"] = SERVE_BQ_DATASET_NAME\n",
    "os.environ[\"BATCH_PREDICTION_BQ_TABLE_NAME\"] = SERVE_BQ_TABLE_NAME\n",
    "os.environ[\"SERVE_LIMIT\"] = \"1000\"\n",
    "os.environ[\"BEAM_RUNNER\"] = \"DirectRunner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from src.tfx_pipelines import config\n",
    "importlib.reload(config)\n",
    "\n",
    "for key, value in config.__dict__.items():\n",
    "    if key.isupper(): print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tfx_pipelines import runner\n",
    "\n",
    "pipeline_definition_file = f'{config.PIPELINE_NAME}.json'\n",
    "pipeline_definition = runner.compile_prediction_pipeline(pipeline_definition_file)\n",
    "pipeline_definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2.google.client import AIPlatformClient\n",
    "\n",
    "pipeline_client = AIPlatformClient(\n",
    "    project_id=PROJECT, region=REGION)\n",
    "                 \n",
    "pipeline_client.create_run_from_job_spec(\n",
    "    job_spec_path=pipeline_definition_file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-supply",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

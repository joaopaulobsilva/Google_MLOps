{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "surgical-shopper",
   "metadata": {},
   "source": [
    "# 06 - Test and Deploy Pipeline to AI Platform Managed Pipelines\n",
    "\n",
    "The purpose of this notebook is to compile and run the TFX pipeline to AI Platform Managed Pipelines. The notebook covers the following tasks:\n",
    "1. Test the pipeline locally using local runner.\n",
    "2. Set the pipeline deployment configuration.\n",
    "3. Build Container Image\n",
    "4. Compile TFX Pipeline\n",
    "5. Submit a pipeline job to AI Platform Pipelines (Managed)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-environment",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import kfp\n",
    "import tfx\n",
    "from tfx.orchestration.local.local_dag_runner import LocalDagRunner\n",
    "import tensorflow as tf\n",
    "import ml_metadata as mlmd\n",
    "from ml_metadata.proto import metadata_store_pb2\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "print(\"Tensorflow Version:\", tfx.__version__)\n",
    "print(\"KFP Version:\", kfp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-theorem",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r src/raw_schema/.ipynb_checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'ksalama-cloudml' # Change to your project Id.\n",
    "REGION = 'us-central1'\n",
    "BUCKET = 'ksalama-cloudml-us' # Change to your bucket.\n",
    "\n",
    "CICD_IMAGE_NAME = 'cicd:latest'\n",
    "CICD_IMAGE_URI = f\"gcr.io/{PROJECT}/{CICD_IMAGE_NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-poultry",
   "metadata": {},
   "source": [
    "## Build CI/CD  Container Image for Cloud Build\n",
    "\n",
    "This is the runtime environment where the steps of testing and deploying the model will be executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $CICD_IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud builds submit --tag $CICD_IMAGE_URI build/. --timeout=15m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-samba",
   "metadata": {},
   "source": [
    "## 1. Run the Pipeline CICD steps locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-health",
   "metadata": {},
   "source": [
    "### Set pipeline configurations for the local run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-pregnancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"DATASET_DISPLAY_NAME\"] = 'chicago_taxi_tips'\n",
    "os.environ[\"MODEL_DISPLAY_NAME\"]  =  'chicago_taxi_tips_classifier_v1'\n",
    "os.environ[\"PROJECT\"] = 'ksalama-cloudml'\n",
    "os.environ[\"REGION\"] = 'us-central1'\n",
    "os.environ[\"GCS_LOCATION\"] = f\"gs://{BUCKET}/ucaip_demo/chicago_taxi/pipelines_local_runner\"\n",
    "os.environ[\"TRAIN_LIMIT\"] = \"8500\"\n",
    "os.environ[\"TEST_LIMIT\"] = \"1500\"\n",
    "os.environ[\"BEAM_RUNNER\"] = \"DirectRunner\"\n",
    "os.environ[\"TRAINING_RUNNER\"] = \"local\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipelines import config\n",
    "for key, value in config.__dict__.items():\n",
    "    if key.isupper(): print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-testing",
   "metadata": {},
   "source": [
    "### Congifure local metadata store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-snapshot",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLMD_SQLLITE = 'mlmd.sqllite'\n",
    "\n",
    "gcs_location = os.environ[\"GCS_LOCATION\"]\n",
    "print(f\"artifacts location: {gcs_location}\")\n",
    "\n",
    "if tf.io.gfile.exists(gcs_location):\n",
    "    print(\"Removing previous artifacts...\")\n",
    "    tf.io.gfile.rmtree(gcs_location)\n",
    "\n",
    "if tf.io.gfile.exists(MLMD_SQLLITE):\n",
    "    print(\"Removing local mlmd SQLite...\")\n",
    "    tf.io.gfile.remove(MLMD_SQLLITE)\n",
    "\n",
    "metadata_connection_config = metadata_store_pb2.ConnectionConfig()\n",
    "metadata_connection_config.sqlite.filename_uri = MLMD_SQLLITE\n",
    "metadata_connection_config.sqlite.connection_mode = 3\n",
    "print(\"ML metadata store is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-vanilla",
   "metadata": {},
   "source": [
    "### Run the pipeline locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-interpretation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipelines import training_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-memorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_root = os.path.join(\n",
    "    config.ARTIFACT_STORE_URI,\n",
    "    config.PIPELINE_NAME,\n",
    ")\n",
    "\n",
    "runner = LocalDagRunner()\n",
    "\n",
    "pipeline = training_pipeline.create_pipeline(\n",
    "    metadata_connection_config=metadata_connection_config,\n",
    "    pipeline_root=pipeline_root,\n",
    "    num_epochs=50,\n",
    "    batch_size=512,\n",
    "    learning_rate=0.0003,\n",
    "    hidden_units=\"256,128\",\n",
    ")\n",
    "\n",
    "runner.run(pipeline)\n",
    "\n",
    "print(\"Pipeline finished exection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-picking",
   "metadata": {},
   "source": [
    "### Set the pipeline configurations for the AI Platform run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-payment",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 'tfx-0-30'\n",
    "os.environ[\"DATASET_DISPLAY_NAME\"] = 'chicago_taxi_tips'\n",
    "os.environ[\"PIPELINE_NAME\"] = f'chicago_taxi_tips_train_pipeline_{VERSION}'\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"REGION\"] = REGION\n",
    "os.environ[\"GCS_LOCATION\"] = f\"gs://{BUCKET}/ucaip_demo/chicago_taxi/pipelines_managed_runner\"\n",
    "os.environ[\"TRAIN_LIMIT\"] = \"85000\"\n",
    "os.environ[\"TEST_LIMIT\"] = \"15000\"\n",
    "os.environ[\"BEAM_RUNNER\"] = \"DataflowRunner\"\n",
    "os.environ[\"TRAINING_RUNNER\"] = \"caip\"\n",
    "os.environ[\"IMAGE_URI\"] = f\"gcr.io/{PROJECT}/chicago_taxi_tips:{VERSION}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-student",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipelines import config\n",
    "\n",
    "import importlib\n",
    "importlib.reload(config)\n",
    "\n",
    "for key, value in config.__dict__.items():\n",
    "    if key.isupper(): print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-publisher",
   "metadata": {},
   "source": [
    "### Build container image\n",
    "\n",
    "This is the tfx runtime environment for the training pipeline steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-edwards",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud builds submit --tag $IMAGE_URI . --timeout=15m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-supplier",
   "metadata": {},
   "source": [
    "### Compile pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-iceland",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipelines import runner\n",
    "\n",
    "pipeline_definition_file = runner.compile_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-strip",
   "metadata": {},
   "source": [
    "### Submit run to AI Platform Managed Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2.google.client import AIPlatformClient\n",
    "\n",
    "pipeline_client = AIPlatformClient(\n",
    "    project_id=PROJECT, region=REGION)\n",
    "                 \n",
    "pipeline_client.create_run_from_job_spec(\n",
    "    job_spec_path=pipeline_definition_file,\n",
    "    parameter_values={\n",
    "        'learning_rate': 0.003,\n",
    "        'batch_size': 512,\n",
    "        'hidden_units': '128,128',\n",
    "        'num_epochs': 30,\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-monkey",
   "metadata": {},
   "source": [
    "![Pipeline execution](imgs/managed-pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-observation",
   "metadata": {},
   "source": [
    "## 2. Execute the Model Deployment CI/CD rountine in Cloud Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-speaking",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
